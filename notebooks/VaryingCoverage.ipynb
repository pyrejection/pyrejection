{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "from pyrejection.experiments import run_experiments\n",
    "from pyrejection.evaluation import (get_ct_summaries, get_nl_summaries,\n",
    "                                    get_conditional_error, standard_fig_style,\n",
    "                                    render_svg_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'accuracy'\n",
    "classifier = 'logreg'\n",
    "random_state = 0\n",
    "base_cache_dir='results_cache'\n",
    "\n",
    "datasets = [\n",
    "    'exp-noisy-letter-recognition',\n",
    "]\n",
    "coverage_configurations = {\n",
    "    'base': {'nl_rate_pairs': [(1, 0)]},\n",
    "    'reduced_rate': {'nl_rate_pairs': [(0.4, 0)]},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_results = {}\n",
    "for label, config in coverage_configurations.items():\n",
    "    print('Starting experiments for config:', label)\n",
    "    cache_dir = os.path.join(base_cache_dir, label)\n",
    "    config_results[label] = run_experiments(\n",
    "        [metric],\n",
    "        [classifier],\n",
    "        datasets,\n",
    "        random_states=[random_state],\n",
    "        worker_count=3,\n",
    "        cache_dir=cache_dir,\n",
    "        drop_test_preds=True,\n",
    "        discard_results=False,\n",
    "        **config\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tradeoff_rows = []\n",
    "for label, exp_results in config_results.items():\n",
    "    for exp_result in exp_results:\n",
    "        dataset = exp_result['config']['dataset']\n",
    "        ct_summaries = get_ct_summaries(exp_result)\n",
    "        for summary in get_ct_summaries(exp_result):\n",
    "            tradeoff_rows.append({\n",
    "                'coverage_config': 'ct',\n",
    "                'dataset': dataset,\n",
    "                'rejection': 1 - summary['coverage'],\n",
    "                'conditional_error': get_conditional_error(summary),\n",
    "            })\n",
    "        for summary in get_nl_summaries(exp_result):\n",
    "            tradeoff_rows.append({\n",
    "                'coverage_config': label,\n",
    "                'dataset': dataset,\n",
    "                'rejection': 1 - summary['coverage'],\n",
    "                'conditional_error': get_conditional_error(summary),\n",
    "            })\n",
    "tradeoffs_df = pd.DataFrame(tradeoff_rows)\n",
    "# Filter fully-rejecting classifiers.\n",
    "tradeoffs_df = tradeoffs_df[tradeoffs_df['rejection'] < 1]\n",
    "\n",
    "config_label_map = {\n",
    "    'ct': 'CT',\n",
    "    'base': 'NL θ=1',\n",
    "    'reduced_rate': 'NL θ=0.4  ',\n",
    "}\n",
    "\n",
    "def plot_tradeoff(dataset, configs):\n",
    "    plot_tradeoffs_df = tradeoffs_df.copy()\n",
    "    plot_tradeoffs_df = plot_tradeoffs_df[(plot_tradeoffs_df['dataset'] == dataset) &\n",
    "                                          plot_tradeoffs_df['coverage_config'].isin(configs)]\n",
    "    plot_tradeoffs_df['coverage_config'] = plot_tradeoffs_df['coverage_config'].map(config_label_map)\n",
    "    colours = sns.color_palette(\"YlOrRd_r\", len(configs)).as_hex()\n",
    "    fig = px.scatter(plot_tradeoffs_df, x='rejection', y='conditional_error', color='coverage_config',\n",
    "                     color_discrete_map={config_label_map[key]: colour\n",
    "                                         for key, colour in zip(configs, colours)})\n",
    "    standard_fig_style(fig)\n",
    "    fig.update_layout({\n",
    "        'width': 550,\n",
    "        'legend_orientation': 'h',\n",
    "        'legend': {'x': 0, 'y': 1.1},\n",
    "        'legend_title_text': '',\n",
    "        'xaxis_title': 'Rejection Rate',\n",
    "        'yaxis_title': 'Conditional Error Rate',\n",
    "        'xaxis': {'range': (-0.05, 1)}\n",
    "    })\n",
    "    fig.update_traces({\n",
    "        'marker': {\n",
    "            'size': 10,\n",
    "        }\n",
    "    })\n",
    "    print(dataset)\n",
    "    render_svg_fig(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tradeoff('exp-noisy-letter-recognition', ['base', 'reduced_rate', 'ct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
